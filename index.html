<!-- saved from url=(0031)https://csgaobb.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
<title>Bin-Bin Gao's homepage</title>
<link rel="shortcut icon" href="./Imgs_files/binbin_favicon.ico">
<meta content="Bin-Bin Gao, È´òÊñåÊñåÔºåcsgaobb.github.io" name="keywords">
<style media="screen" type="text/css"></style>

<link href="./main_files/homepage.css" rel="stylesheet" type="text/css">

<!-- Google Analytics -->
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-69879514-1']);
    _gaq.push(['_trackPageview']);

    (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>

</script>
<script src='./main_files/hidebib.js' type="text/javascript"></script>
</head>

<!-- Google custom search -->
  <script type="text/javascript">
    (function() {
    var cx = '015564147751910566765:wsger_p3dsg';
    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
    '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
    })();
  </script>


<body>
<div class="searchbox">
     <gcse:searchbox-only resultsUrl="./search.html"
           autoCompleteMaxCompletions="5"
           autoCompleteMatchType="any"/>
     </gcse:searchbox-only>
    <a href="https://bestimage.qq.com/" target="_blank">
    <img title="YouTuLab"  class="youtu" src="./Imgs_files/youtu.png">
    </a>
    <!--
    <a href="http://www.nju.edu.cn" target="_blank">
    <img title="Nanjing University"  class="nju" src="./Imgs_files/nju.jpg">
    </a>
    <a href="http://www.lamda.nju.edu.cn/" target="_blank">
    <img title="LAMDA"  class="lamda" src="./Imgs_files/lamda.png">
    </a>
    -->
</div>
<div style="margin-bottom: 0em; border: 0px solid #ddd; background-color: #fff; padding: 1em; height: 235px;">
<div style="margin: 0px auto; width: 100%;">
<a href="https://csgaobb.github.io/" target="_blank">
<img title="Bin-Bin Gao" class="myphoto1"  src="./Imgs_files/gaobb.JPG">
</a>
<div style="padding-left: 15em; padding-right: 2em;vertical-align: top; height: 180px;">
<span style="line-height: 100%; font-size: 20pt;padding-top: 5em">Bin-Bin GaoÔºàÈ´òÊñåÊñåÔºâ</span><br></br>
<span> Ph.D., Senior Researcher</span> <br></br>
<span><a href="https://ai.qq.com/hr/youtu.shtml">YouTu Lab, </a></span> 
<span><a href="http://www.tencent.com/en-us/index.html">Tencent</a></span> <br>
<span><a href="http://www.lamda.nju.edu.cn/"><s>LAMDA Group, </s></a></span> 

<span><a href="https://www.nju.edu.cn/"><s>Nanjing University</s></a></span> <br></br>

<span>Shenzhen 518057, China</span><br>
<span><strong>Email: <a href="mailto:csgaobb@gmail.com"></strong>csgaobb@gmail.com</a>  or <a href="mailto:gaob@lamda.nju.edu.cn"></strong>gaobb@lamda.nju.edu.cn</a></span> <br>

<a href="https://github.com/gaobb" target="about_blank"><img src="./Imgs_files/github.svg" style="height:25px;width:25px;margin:10px;border:0;-moz-box-shadow: 0px 0px 0px #888;
  -webkit-box-shadow: 0px 0px 0px #888;
  box-shadow: 0px 0px 0px #888;"></a> 
<a href="https://weibo.com/csgaobb" target="about_blank"><img src="./Imgs_files/weibo.png" style="height:25px;width:25px;margin:10px;border:0;-moz-box-shadow: 0px 0px 0px #888;
  -webkit-box-shadow: 0px 0px 0px #888;
  box-shadow: 0px 0px 0px #888;"></a>
<a href="https://orcid.org/0000-0003-2572-8156" target="about_blank"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="height:25px;width:25px;margin:10px;border:0;-moz-box-shadow: 0px 0px 0px #888;
  -webkit-box-shadow: 0px 0px 0px #888;
  box-shadow: 0px 0px 0px #888;"></a></span>
<br><br><br>
<span>
<h3>
  <p align="left">
    <a href="https://csgaobb.github.io/#Biography">Biography</a> 
    <font size="4">|</font> <a href="https://csgaobb.github.io/#News">News</a> 
    <font size="4">|</font> <a href="https://csgaobb.github.io/#Selected Publications">Publications</a> 
    <font size="4">|</font> <a href="https://csgaobb.github.io/#Professional Activities">Activities</a> 
    <font size="4">|</font> <a href="https://csgaobb.github.io/">Home</a> 
</p>
</h3>
</span>
<br>
</div>
</div>
</div>
<hr>





<div style="clear: both;">
<div class="section">
<h2> <a name="Biography">Biography</a>
<!--[<a href="./main_files/GAOBB_CV.pdf">CV</a>]-->
</h2>

<div style="text-align:justify;">
<div class="paper" >
I am a Senior Researcher at <a href="https://bestimage.qq.com/"> Tencent YouTu Lab</a> in Shenzhen.<!--, led by Prof. <a href="http://jiaya.me/">Jiaya Jia</a> (IEEE Fellow)--> 
Previously, I received my Ph.D. in <a href="http://www.nju.edu.cn/">Nanjing University</a> at <a href="http://www.lamda.nju.edu.cn/">LAMDA Group</a>, 
led by Prof. <a href="https://cs.nju.edu.cn/zhouzh/" target="_blank"> Zhi-Hua Zhou</a> (foreign member of the Academy of Europe, ACM/AAAI/AAAS/IEEE/IAPR Fellow), 
advised by Prof. <a href="http://cs.nju.edu.cn/wujx">Jianxin Wu</a> (member of the Thousand Talents Plan). 
Before that, I got my B.S. degree in applied mathematics in 2010, and received my M.S. degree in 2013 from <a href="http://swu.edu.cn/">Southwest University</a>, 
Chongqing China. My research interests include computer vision and machine learning, especially visual recognition and deep learning. 
I have severed as a reviewer (or PC member) for CVPR, ICCV, NeurIPS, AAAI, ECCV, ACCV, WACV, TIP, TKDE, TMI, TII, TNNLS, NN, Neurocomputing etc.
<br>
</div>
</div>
</div>
</div>


<div style="clear: both;">
  <div class="section">
  <h2><a name="Research">Research</a></h2>
  <div class="paper">
  <ul>
  <ol> 
  <li><strong>General Object Recognition</strong></li>
  <ul>
  <li>Multi-Label Image Recognition [<a href="https://ieeexplore.ieee.org/document/9466402">TIP 21</a>]
  <li>Change Detection [<a href="https://arxiv.org/pdf/2206.07557.pdf">PR 22</a>]</li>
  <li>Open-Vocabulary Object Detection</li>
  </ul>
  <li><strong>Few-Shot Learning</strong></li>
  <ul>
  <li>Image Classification [<a href="https://arxiv.org/pdf/2304.10093.pdf">IJCAI 23</a>]</li>
  <li>Semantic Segmentation [<a href="https://ieeexplore.ieee.org/document/9773019">TMM 22</a>]</li>
  <li>Object Detection and Instance Segmentation [<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/764ba7236fb63743014fafbd87dd4f0e-Paper-Conference.pdf">NeurIPS 22</a>]</li>

  </ul>
  <li><strong>Continual Learning</a></strong></li>
  <ul>
  <li>Image Classification [<a href="https://ieeexplore.ieee.org/abstract/document/10347466">TMM 23</a>]</li>
  <li>Object Detection [<a href="https://cs.nju.edu.cn/_upload/tpl/00/ed/237/template237/paper/AAAI2016_D3.pdf">AAAI 24</a>]</li>
  </ul>
  <li><strong>Anomaly Detection</strong></li>
  <ul>
  <li>Unified Anomaly Detection</li>
  <li>Universal Anomaly Detection</li>
  <li>Fully Unsupervised Anomaly Detection [<a href="">CVPR 24</a>]</li>
  </ul>
  <li><strong>Earlier Works</strong></li>
  <ul>
  <li>Deep Label Distribution Leaning 
    [<a href="https://ieeexplore.ieee.org/abstract/document/7890384/">TIP 17</a>]  
    [<a href="https://www.ijcai.org/proceedings/2018/0099.pdf">IJCAI 18</a>]
  </li>
  <li>Visual (Image and Video) Representation 
    [<a href="https://cs.nju.edu.cn/_upload/tpl/00/ed/237/template237/paper/AAAI2016_D3.pdf">AAAI 16</a>]
  </li>
  <li>Support Vector Machine 
    [<a href="https://ieeexplore.ieee.org/document/7424278">ICMLA 15</a>]
  </li>
  </ul>
  <br>
  üî•üî•üî•If you have interests on above topics, please directly send me email to <a href="mailto:csgaobb@gmail.com">csgaobb at gmail dot com</a>, and remote cooperations are welcomed.
  </br>
  <br>
  üî•üî•üî•<font color="red"> I am recruiting self-motivated interns in computer vision. If you are interested in, please directly send your CV to <a href="mailto:danylgao@tencent.com">my email danylgao at tencent dot com</a>,
    <a href="https://csgaobb.github.io/internjd.html"> [ÊãõËÅòJD]</a>.
  </font>
  </br>
  <div class="spanner"></div>
  </div>
  </div>
  </div>

  

<div style="clear: both;">
<div class="section">
  <h2><a name="News">News</a></h2>
  <div class="paper">
    <ul>
    <li> Mar. 27, 2024: üéâüéâüéâ I will be serving as an Area Chair for <a href="https://neurips.cc/">NeurIPS 2024</a>. It‚Äôs an honor to take on this role, and I‚Äôm looking forward to contributing to this conference.</li>
    <li> Feb. 27, 2024: üéâüéâüéâ A paper on fully unsupervised anomaly detection benchmark is accepted by <a href="https://cvpr.thecvf.com/">CVPR 2024</a>.</li>  
    <li> Dec. 09, 2023: üéâüéâüéâ Three papers on anomaly detection, continual detection and matched detection are accepted by <a href="https://aaai.org/Conferences/AAAI-24/">AAAI 2024</a>.</li>  
    <li> Nov. 23, 2023: A paper on cross-modal continual learning is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046"> IEEE Trans. Multimedia</a>.</li>
    <li> Mar. 28, 2023: A paper on label distribution learning is accepted by <a href="https://www.editorialmanager.com/NCA"> Neural Computing and Applications</a>.</li>
    <li> Feb. 24, 2023: A paper on few-shot image classification is accepted by <a href="https://ijcai-23.org/">IJCAI-2023</a>.</li>
    <li> Jan. 01, 2023: A paper on change detection is accepted by <a href=https://www.sciencedirect.com/journal/pattern-recognition"> Pattern Recognition</a>.</li>
    <li> Nov. 18, 2022: A paper on few-shot image classification is accepted by <a href="https://aaai.org/Conferences/AAAI-23/">AAAI 2023</a>.</li>
    <li> Sep. 15, 2022: A paper on few-shot object detection and instance segmentation is accepted by <a href=https://nips.cc/Conferences/2022/"> NeurIPS 2022</a>.</li> 
    <li> Jul. 3, 2022: A paper on few-shot image classification is accepted by <a href=https://eccv2022.ecva.net/"> ECCV 2022</a>.</li>
    <li> Jun. 30, 2022: Three papers on continual abnormal detection, few-shot and multi-label image classification are accepted by <a href="https://2022.acmmm.org/"> ACM MM 2022</a>.</li>
    <li> May. 06, 2022: A journal paper on few-shot semantic segmentation is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046"> IEEE Trans. Multimedia</a>.</li>
    <li> Jun. 05, 2021: A journal paper on multi-label image recognition is accepted by <a href="http://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing"> IEEE Trans. Image Processing</a>.</li>
    <li> Jul. 26, 2018, I joined Tencent and became a researcher of YouTu X-Lab.
    <li> Jun. 21, 2018, I got my Ph.D. in <a href="http://www.nju.edu.cn/">Nanjing University</a> at <a href="https://csgaobb.github.io/">LAMDA GROUP</a>, advised by Prof. <a href="http://cs.nju.edu.cn/wujx">Jianxin Wu</a>. 
    <li> May 21, 2018, I defended my Ph.D. thesis.
    <li> Apr. 17, 2018: A paper is accepted by <a href="https://www.ijcai-18.org/">IJCAI 2018</a> (Acceptance Rates: 710/3470=20.46%).
    <li> Mar. 28, 2018: A paper (in Chinese) is accepted by <a href="http://engine.scichina.com/publisher/scp/journal/Sci%20Sin%20Info%20F?slug=Overview">SCIENTIA SINICA Informatics</a>. 
    <li> Jul. 31, 2017: A paper accepted to <a href="http://iccv2017.thecvf.com/">ICCV 2017</a>.
    <li> Mar. 26, 2017: A journal paper on deep label distribution learning is accepted by <a href="http://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing"> IEEE Trans. Image Processing</a>.</li>
    <li> Dec. 11-17, 2015: Attended <a href="http://pamitc.org/iccv15/"> ICCV 2015</a>.</li>
    <li> Nov. 13, 2015: A paper accepted for <a href="http://aaai.org/"> AAAI 2016</a>. </li>
    <li> Oct. 10, 2015: Two papers accepted for ICCV 2015 Workshop. </li>
    <li> Sep. 20, 2015: First runner-up in <a href="http://gesture.chalearn.org/"> Cultural Event Recognition </a> at ICCV 2015. (with X.-S Wei and J. Wu)</li>
    <!--<li> Sep. 20, 2015: The fourth place in <a href="http://gesture.chalearn.org/"> Apprament Age Estimation </a> at ICCV 2015. </li>-->
    </ul>
  </div>
</div>
</div>



<div class="section">
<h2><a name="Selected Publications">Selected Publications</a></h2>
<p>
[<a href="https://csgaobb.github.io/fullpubs.html">Full Publications</a>]
[<a href="http://scholar.google.com/citations?user=yYviZ-oAAAAJ&hl=en">Google Scholar</a>]
</p>

<ul>
<li>
  <p>
  <a href=https://doi.org/10.1609/aaai.v38i7.28537>Learning Task-Aware Language-Image Representation for Class-Incremental Object Detection</a>
  <br> H. Zhang*, <strong>B.-B. Gao*</strong>, Y. Zeng, X. Tian, X. Tan#, Z. Zhang, Y. Qu, J. Liu and Y. Xie
  <br> AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), Vancouver, Canada, Feb 2024, pp.7096-7104. 
  <br>
  [<a href="">Code, Coming soon</a>]
  [<span style="color:red;"><strong>CCF-A</strong></span>]<br>
</p>
</li>
</ul>

<ul>
<li>
<p>
  <a href=10.1109/TMM.2023.3340551>Cross-Modal Alternating Learning with Task-Aware Representations for Continual Learning</a>
  <br> W. Li*, <strong>B.-B. Gao*</strong>#, B. Xia, J. Wang, J. Liu, Y. Liu, C. Wang and F. Zheng  
  <br> IEEE Transactions on Multimedia (<strong>IEEE TMM</strong>), 2023, in press. 
  <br> 
  [<a href="https://github.com/vijaylee/ALTA">Code</a>] 
  [<span style="color:red;"><strong>CCF-B, SCI-1, IF:7.3</strong></span>] 
  <!--
  <br>
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/cross-modal-alternating-learning-with-task/continual-learning-on-cifar100-10-tasks">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/cross-modal-alternating-learning-with-task/continual-learning-on-tiny-imagenet-10tasks">
  -->
</p>
</li>
</ul>

<ul>
<li>
<p>
  <a href=https://doi.org/10.1016/j.patcog.2023.109384>How to Reduce Change Detection to Semantic Segmentation</a>
  <br>G.-H. Wang, <strong>B.-B. Gao#</strong> and C. Wang
  <br>Pattern Recognition (<strong>PR</strong>), 2023. 
  <br>
  [<a href="https://github.com/DoctorKey/C-3PO">Code</a>]
  [<span style="color:red;"><strong>CCF-B, SCI-1, IF:8.0</strong></span>]
  <!--
  <br>
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/how-to-reduce-change-detection-to-semantic/change-detection-on-changesim-1">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/how-to-reduce-change-detection-to-semantic/change-detection-on-pcd">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/how-to-reduce-change-detection-to-semantic/scene-change-detection-on-vl-cmu-cd">
  -->
</p> 
</li>
</ul>

<!--
<ul>
<li>
<p>
  <a href=https://doi.org/10.1007/s00521-023-08563-4><strong>Jointly learning distribution and expectation in a unified framework for facial age and attractiveness estimation</strong></a>   
  <br> <strong>B.-B. Gao</strong>#
  <br> Neural Computing and Applications (<strong>NCA</strong>), 35(21):15583-15599, 2023. [<span style="color:red;"><strong>CCF-C, SCI-3, IF:6.0</strong></span>]
</p>
</li>
</ul>
-->

<ul>
<li>
<p>
  <a href=https://proceedings.neurips.cc/paper_files/paper/2022/file/764ba7236fb63743014fafbd87dd4f0e-Supplemental-Conference.pdf>Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation</a>
  <br><strong>B.-B. Gao#</strong>, X. Chen, Z. Huang, C. Nie, J. Liu, J. Lai, G. Jiang, X. Wang and C. Wang#
  <br> Neural Information Processing Systems (<strong>NeurIPS</strong>), New Orleans, USA, Dec 2022, pp.18640-18652. 
  <br>
  [<a href="https://github.com/gaobb/DCFS">Code</a>]
  [<a href="https://csgaobb.github.io/Projects/DCFS.html">Project</a>]
  [<a href="https://nips.cc/media/neurips-2022/Slides/55372_kHEysnz.pdf">Slides</a>]
  [<a href="https://csgaobb.github.io/Projects/mscoco-fsod.html">FSOD-Leaderboard</a>]
  [<span style="color:red;"><strong>CCF-A</strong></span>]
  <!--
  <br>
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/decoupling-classifier-for-boosting-few-shot/few-shot-object-detection-on-ms-coco-1-shot">	
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/decoupling-classifier-for-boosting-few-shot/few-shot-object-detection-on-ms-coco-10-shot">  
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/decoupling-classifier-for-boosting-few-shot/few-shot-object-detection-on-ms-coco-30-shot">
  -->
</p> 
</li>
</ul>

<ul>
<li>
<p>
  <a href=https://doi.org/10.1109/TMM.2022.3174405>APANet: Adaptive Prototypes Alignment Network for Few-Shot Semantic Segmentation</a>
  <br> J. Chen*, <strong>B.-B. Gao*</strong>#, Z. Lu, J.-H. Xue, C. Wang and Q. Liao
  <br> IEEE Transactions on Multimedia (<strong>IEEE TMM</strong>), 25:4361-4373, 2022. 
  <br> 
  <!--[<a href="">Code</a>]-->
  [<span style="color:red;"><strong>CCF-B, SCI-1, IF:7.3</strong></span>]
</p>
</li>
</ul>
 
<ul>
<li> 
<p>
  <a href=https://doi.org/10.1109/TIP.2021.3088605>Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition</a>
  <br><strong>B.-B. Gao#</strong> and H.-Y. Zhou
  <br> IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 20:5920-5932, 2021. 
  <br> 
  [<a href="https://github.com/gaobb/MCAR">Code</a>]
  [<span style="color:red;"><strong>CCF-A, SCI-1, IF:10.6</strong></span>] 
  <!--
  <br>
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/multi-label-image-recognition-with-multi/multi-label-classification-on-pascal-voc-2012">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/multi-label-image-recognition-with-multi/multi-label-classification-on-pascal-voc-2007">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/multi-label-image-recognition-with-multi/multi-label-classification-on-ms-coco">
  -->
</p> 
</li>
</ul>

<ul>
<li>
<p>
  <a href=https://www.ijcai.org/proceedings/2018/0099.pdf>Age Estimation Using Expectation of Label Distribution Learning</a>
  <br> <strong>B.-B. Gao</strong>, H.-Y. Zhou, J. Wu# and X. Geng
  <br> Int'l Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), Stockholm, Sweden, Jul 2018, pp.712-718. 
  <br>
  [<a href="https://github.com/gaobb/DLDL-v2">Code</a>]
  [<a href="https://csgaobb.github.io/Projects/DLDL-v2.html">Project</a>]
  [<span style="color:red;"><strong>CCF-A</strong></span>]
  <!--
  <br>
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-expectation-of-label-distribution/age-estimation-on-morph-album2">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-expectation-of-label-distribution/age-estimation-on-chalearn-2015">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-expectation-of-label-distribution/age-estimation-on-chalearn-2016">
  <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-expectation-of-label-distribution/attractiveness-estimation-on-scut-fbp">
  -->
</p>  
</li>
</ul>
 
<ul>
<li>
<p>
  <a href=https://doi.org/10.1109/TIP.2017.2689998>Deep Label Distribution Learning with Label Ambiguity</a>
  <br><strong>B.-B. Gao</strong>, C. Xing, C.-W. Xie, J. Wu# and X. Geng
  <br> IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 26(6):2825-2838, 2017. 
  <br> 
  [<a href="https://github.com/gaobb/DLDL">Code</a>]
  [<a href="https://csgaobb.github.io/Projects/DLDL.html">Project</a>]
  [<span style="color:red;"><strong>CCF-A, SCI-1, IF:10.6</strong></span>] 
  <!--
  <br>

  <a href="https://paperswithcode.com/sota/age-estimation-on-morph-album2?p=deep-label-distribution-learning-with-label">
    <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-label-distribution-learning-with-label/age-estimation-on-morph-album2"> 
  </a>
  <a href="https://paperswithcode.com/sota/head-pose-estimation-on-aflw?p=deep-label-distribution-learning-with-label">
    <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-label-distribution-learning-with-label/head-pose-estimation-on-aflw">
  </a>
  <a href="https://paperswithcode.com/sota/semantic-segmentation-on-pascal-voc-2012-1?p=deep-label-distribution-learning-with-label">
     <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-label-distribution-learning-with-label/semantic-segmentation-on-pascal-voc-2012-1"> 
  </a>
	<a href="https://paperswithcode.com/sota/multi-label-classification-on-pascal-voc-2012?p=deep-label-distribution-learning-with-label">   
     <img class="paperwithcode" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-label-distribution-learning-with-label/multi-label-classification-on-pascal-voc-2012"> 
  </a>
  <br>
  -->
</p> 
</li>
</ul>
</div>
</div>

<div style="clear: both;">
  <div class="section">
  <h2> <a name="Professional Activities">Professional Activities</a></h2>
  <div class="paper">
  <ul>
  
  <p><font size="5"> Area Chair:
  <li>
  <a href="https://nips.cc/"> NeurIPS 2024</a>
  </li>
  
  <p><font size="5">Conference Reviewer or PC Member:
  
  <li>
    <a href="https://iclr.cc/Conferences/2023">ICLR 2024</a>,
    <a href="https://aaai.org/Conferences/AAAI-24/">AAAI 2024</a>,
    <a href="https://cvpr.thecvf.com/">CVPR 2024</a>,
    <a href="https://ijcai24.org/">IJCAI-2024</a>,
    <a href="https://icml.cc/Conferences/2024"> ICML 2024</a>,
    <a href="https://eccv.ecva.net/">ECCV 2024</a>
  </li>
  
  <li>
  <a href="https://iclr.cc/Conferences/2023">ICLR 2023</a>,
  <a href="http://wacv2023.thecvf.com">WACV 2023</a>,
  <a href="https://aaai.org/Conferences/AAAI-23/">AAAI 2023</a>,
  <a href="http://cvpr2023.thecvf.com/">CVPR 2023</a>,
  <a href="https://ijcai-23.org/">IJCAI-2023</a>,
  <a href="https://icml.cc/Conferences/2023"> ICML 2023</a>,
  <a href="https://nips.cc/"> NeurIPS 2023</a>
  </li>
  
  <li>
  <a href="https://iclr.cc/Conferences/2022">ICLR 2022</a>,
  <a href="http://wacv2022.thecvf.com">WACV 2022</a>,
  <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a>,
  <a href="http://cvpr2022.thecvf.com/">CVPR 2022</a>,
  <a href="https://ijcai-22.org/">IJCAI-2022</a>,
  <a href="https://nips.cc/Conferences/2022/">NeurIPS-2022</a>
  
  </li>
  <li>
  <a href="http://wacv2021.thecvf.com">WACV 2021</a>,
  <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>,
  <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>,
  <a href="http://iccv2021.thecvf.com/">ICCV 2021</a>
  </li>
  <li>
  <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>,
  <a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a>,
  <a href="http://ecai2020.eu/">ECAI 2020</a>,
  <a href="https://eccv2020.eu/">ECCV 2020</a>,
  <a href="http://accv2020.kyoto/">ACCV 2020</a>
  </li>
  <li>
  <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>,
  <a href="http://iccv2019.thecvf.com/">ICCV 2019</a>, 
  <a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a>
  </li> 
  <li>
  <a href="http://cvpr2018.thecvf.com/">CVPR 2018</a>, 
  <a href="https://eccv2018.org/">ECCV 2018</a>,
  <a href="http://accv2018.net">ACCV 2018</a>
  </li>
  <li>
  <a href="http://cvpr2017.thecvf.com/">CVPR 2017</a>, 
  <a href="http://iccv2017.thecvf.com/">ICCV 2017</a>
  </li>
  <li>
  <a href="http://www.aaai.org/Press/Proceedings/aaai16.php">AAAI 2016</a>
  </li>
  </font></p>
  <p><font size="5">Journal Reviewer: 
  <li><a href="https://mc.manuscriptcentral.com/tip-ieee">IEEE Transactions on Image Processing (TIP)</a></li>
  <li><a href="https://www.journals.elsevier.com/neural-networks/">Neural Networks (NN)</a></li>
  <li><a href="https://mc.manuscriptcentral.com/tnnls">IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</a></li>
  <li><a href="https://mc.manuscriptcentral.com/tii">IEEE Transactions on Industrial Informatics (TII)</a></li>
  <li><a href="https://mc.manuscriptcentral.com/tkde-cs">IEEE Transactions on Knowledge and Data Engineering (TKDE)</a></li>
  <li><a href="https://www.journals.elsevier.com/neurocomputing">Neurocomputing</a></li>
  <li><a href="https://www.editorialmanager.com/RTIP">Journal of Real-Time Image Processing (JRTIP)</a></li>
  <li><a href="https://mc.manuscriptcentral.com/tmi-ieee">IEEE Transactions on Medical Imaging (TMI)</a></li>
  <li><a href="https://www.springer.com/journal/10115">Knowledge and Information Systems (KAIA)</a></li>
  <li><a href="https://www.editorialmanager.com/NCA">Neural Computing and Applications(NCA)</a></li>
  </font></p>
  </ul>
  </div>
  </div>
  </div>

<div style="clear: both;">
<div class="section">
<h2> <a name="Awards and Honors">Awards and Honors</a></h2>
<div class="paper">
<ul>
<li>Top Reviewers in <strong><a href="https://neurips.cc/Conferences/2022/ProgramCommittee">NeurIPS 2022</a></strong>.</li>
<li>Emergency PC Member in <strong><a href="https://ijcai-22.org/">IJCAI 2022</a></strong>.</li>
<li>High-Quality Reviews to <strong><a href="https://eccv2020.eu/">ECCV 2020</strong></a>.</li>
<li><strong>Nanruijibao Scholarship</a></strong> in Nanjing University, 2016.</li>
<li><strong>Outstanding Thesis Award</a></strong> of Southwest University, 2013.</li>
<li><strong>First-class Academic Scholarship</a></strong> of Southwest University, 2011-2012.</li>
<li><strong>Outstanding Undergraduates Awards</a></strong>, 2010.</li>
<li><strong>National Scholarship for Encouragement</a></strong>, 2007-2008 & 2008-2009.</li>
</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2> <a name="Competitions">Competitions</a></h2>
<div class="paper">
<ul>
<li><strong>Winner</strong> in Instance Classification Track at CVPR 2022 CLVision Challenge.</li>
<li><strong>First runner-up</strong> in Cultural Event Recognition at ICCV 2015.(with Xiu-Shen Wei and Jianxin Wu)</li>
<li><strong>Fourth place</strong> in Apprament Age Estimation at ICCV 2015. (with Xu Yang, Chao Xing, Zeng-Wei Huo, Xiu-Shen Wei, Ying Zhou, Jianxin Wu and Xin Geng) </li> 
<li><strong>Meritorious Winner</strong> of Certificate Authority Cup Mathematical Contest in Modeling, 2012.(with Qiu-Lin Li and Hong-Yan Yang)</li>
<li><strong>Second Prize</strong> in China Graduate Mathematical Contest in Modeling (CGMCM), 2011.(with Qiu-Lin Li and Ji-Lian Guo)</li>
<li><strong>Third Prize</strong> in China Undergraduate Mathematical Contest (Mathematics, Finals) (CMC), 2010.</li>
<li><strong>First Prize</strong> in China Undergraduate Mathematical Contest (Mathematics, Preliminaries) (CMC), 2009.</li>
</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2> <a name="Teaching Assistants">Teaching Assistants</a></h2>
<div class="paper">
<ul>
<li><strong><a href="https://cs.nju.edu.cn/wujx/teaching_PR.html">Pattern Recognition</a></strong> (<small>for undergraduate and graduated students. Spring, 2017.</small>)</li>
<ol> 
<li><a href="http://cs.nju.edu.cn/wujx/teaching_PR.html">Course Page</a></li>
<li><a href="./teaching.html">Assignments Page</a></li>
</ol>
<li><strong><a href="https://cs.nju.edu.cn/tb/prob.htm">Probability and Statistics</a></strong> (<small>for undergraduate students. Spring, 2017.</small>)</li>
<ol> 
<li><a href="https://cs.nju.edu.cn/tb/prob.htm">Course Page</a></li>
<li><a href="./teaching.html">Assignments Page</a></li>
</ul>
<div class="spanner"></div>
</div>
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Correspondence</h2>
<div class="paper">
<ul>
<p><font size="5"><strong>Email:<a href="mailto:csgaobb@gmail.com"></strong> csgaobb@gmail.com</a></font></p>
<p><font size="5">Bin-Bin Gao</font></p>
<p><font size="5">YouTu Lab, Tencent</font></p>
<p><font size="5">18F, Malata Building, Kejizhongyi Road</font></p>
<p><font size="5">Nanshan District, Shenzhen 518057, P.R. China</font></p>
</ul>
</div>
</div>
</div>
<hr>

<!--<div style="clear: both;">
<div class="section">-->
<!-- Êù•ÂøÖÂäõCityÁâàÂÆâË£Ö‰ª£Á†Å 
<div id="lv-container" data-id="city" data-uid="MTAyMC8zMTM0MC83OTAz">
<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
</script>
<noscript>‰∏∫Ê≠£Â∏∏‰ΩøÁî®Êù•ÂøÖÂäõËØÑËÆ∫ÂäüËÉΩËØ∑ÊøÄÊ¥ªJavaScript</noscript>
</div>
-->
<!-- CityÁâàÂÆâË£Ö‰ª£Á†ÅÂ∑≤ÂÆåÊàê -->
<!--</div>
</div>-->


<div style="clear: both;">
<div class="clustrmapsection">
     <script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=lFQx-PXyHBymj3FqoTTJWIaTiAap63Cpqt0uNyBYmBU"></script>
</div>
</div>

<div style="clear:both;">
<p align="right"><font size="2"><a href="https://csgaobb.github.io/">Updated on Mar. 27, 2024.</a></font></p>
</div>

</body>
</html>
